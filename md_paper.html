<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>GenAD: paper</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">GenAD
   </div>
   <div id="projectbrief">Generalized Input Automatic Differentiation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_paper.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">paper </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><hr/>
<p> affiliations:</p>
<ul>
<li>index: 1 name: "Harvard University, Division of Continuing Education"</li>
<li>index: 2 name: "Harvard University, Dept. of Computer Science"</li>
<li>index: 3 name: "Harvard University, Institute for Applied Computational Science"</li>
<li>index: 4 name: "Scientific Simulations, LLC." authors:</li>
<li>affiliation: 1 name: "Neil Warren^[Footnote description.]" orcid: 0000-0001-7848-4226</li>
<li>affiliation: 2 name: "Aakash Mishra^[Footnote description.]" orcid: ~</li>
<li>affiliation: 3 name: "David Sondak^[Footnote description.]" orcid: ~</li>
<li>affiliation: 4 name: "Andrew Kirby^[Footnote description.]" orcid: ~ bibliography: paper.bib date: "03 11 2021" tags:</li>
<li>"automatic differentiation"</li>
<li>"algorithmic differentiation" title: "GenAD: A Generalized Input Automatic Differentiation Library in C++" <hr/>
</li>
</ul>
<h1>Summary</h1>
<p>From mathematical optimization to neural network training, the need to efficiently compute derivatives of functions containing tens or even thousands of variables and operations has become ubiquitous in scientific computing [<b>reference!</b>] and scientific machine learning [:v18:17-468]. Given the computational drawbacks of performing symbolic differentiation, which quickly becomes intractable under moderate functional complexity [<b>reference to computational complexity of symbolic differentiation</b>] for even the most sophisticated computer algebra systems[<b>cite some of the systems</b>], automatic differentiation has emerged as a powerful method to compute derivatives. The emerging field of differential programming [<b>references</b>] provides substantial support for writing differential scientific programs. Indeed, modern programming languages, such as the Julia Programming Language [<b>cite!</b>], natively support automatic differentiation. Within the machine learning community, several popular open source libraries include automatic differentiation functionality including Pytorch [], [] and Tensorflow []. While powerful and extensible, these libraries are limited in the scope and form of the input that they can accept. In particular, users of these libraries leverage computer source code (often Python) to input the function to be differentiated or write source code to derive the internal representation of the functions. For functions derived outside of the computational environment, definition and data input is a largely manual process.</p>
<p>The GenAD library presented in this work utilizes forms of generalized input (e.g., non-specific to the computational environment), such as scientific documents and text strings. Acceptance of more generalized forms of input allows for the efficient automation of automatic differentiation for functions derived in varied computational environments. This is particularly useful for large functions of tens or thousands of variables, for example, as provided by output in text form from documents or as output from libraries written in other languages with incompatible data types.</p>
<h1>Statement of need</h1>
<p>In many applications, scientists may use a software library that lacks built-in efficient automatic differentiation functionality.For functions involving a large number of variables (e.g. hundreds or thousands), the data input process for providing that function to a standard machine learning library such as Pytorch or Tensorflow can be exceedingly time consuming and prone to error. Thus, there is a need for an automatic differentiation library that can read in the function to be evaluated in a generalized form, such as raw text, differentiate it to machine precision, and easily write out the result to a file by an external software library [DLS: I don't understand thie last part starting at easily. Let's discuss].</p>
<p>GenAD is a C++ library that applies Dijkstra's shunting yard algorithm [] to pre-process textual function inputs along with point vectors and derivative seed vectors, and then applies forward and reverse mode automatic differentiation algorithms to develop a well-formed Jacobian matrix [<em>The previous sentence is way too long. Split it into 2 or 3 sentences.</em>]. In contrast, most existing popular automatic differentiation libraries take functional input in the form of a computer program's source code (often Python) utilizing specialized data structures and previously declared variables and constants []. This makes the process of applying automatic differentiation to functions from textual sources a manual task. GenAD accepts raw textual input, e.g., "f(x0,y0) = x0 * cos(y0)," from the command line or a text file, such as a scientific document.</p>
<h1>Features</h1>
<p>GenAD utilizes functional descriptions as input and provides a complete well-formed Jacobian matrix as output. The user may optionally select either forward mode or reverse mode automatic differentiation, the relative advantages and disadvantages of which have been discussed at length in the literature [:journals/corr/abs-1811-05031] [:v18:17-468].</p>
<p>As shown in {fig:Parsing}, the GenAD shunting yard pre-processing implementation achieves approximately O(n) time complexity over the number of generated tokens (approximately proportional to the number of elementary functions in the input function). This was confirmed using a standard laptop with an Intel® Core™ i7-8550U CPU running 100 averaged trials with functions of up to 524,288 elementary operations and independent variables. Independent of the functional complexity, given that variable names given in text (e.g., “x0,” "x1," ... “x524287”) grow in length, parsing text for variable names in the tokenizer causes the shape of the curve to become more quadratic as the input size increases.</p>
<div class="image">
<img src="processing.png"  alt=" Parsing tokenization scaling.\label{fig:Parsing}"/>
</div>
<p>Given the algorithmic constraints of forward mode automatic differentiation, which computes partial derivatives for each independent variable at each computational node, reverse mode provides for more efficient computation of derivatives for functions with a large numbers of independent variables. Reverse mode, in contrast, requires the computation of an adjoint tree from a first pass through the function tokens, which adds a small amount of computational overhead and thus is not optimal for functions of only a few variables. Figure {fig:Parsing} shows the computational time complexity for the parsing and evaluation of the Jacobian for functions of 1 to $2^{18}$ variables.</p>
<div class="image">
<img src="fwd_vs_rev.png"  alt=" Forward vs. Reverse Mode.\label{fig:fwdrev }"/>
</div>
<h1>Acknowledgements</h1>
<p>GenAD was developed as an extension of a group project developed in the course "Systems Development for Computational
Science," CS-107, at Harvard University in the Fall of 2020 under the instruction of Dr. David Sondak, Harvard Institute for Applied Computational Science, and Dr. Andrew Kirby, Research Scientist at Scientific Simulations, LLC., and in collaboration with Leo Landau and Samson Negassi.</p>
<h1>References</h1>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.6 </li>
  </ul>
</div>
</body>
</html>
